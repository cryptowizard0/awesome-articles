# 我们如何构建多智能体研究系统

 #claude #agent #multi-agent
 
原文：https://www.anthropic.com/engineering/multi-agent-research-system
[Anthropic 工程团队](https://www.anthropic.com/engineering)

本文详细介绍了 Anthropic 工程团队如何构建多智能体研究系统。文章深入探讨了多智能体系统的优势，如通过并行操作和分工协作提升研究效率；解析了采用“编排器-工作者”模式的系统架构；分享了关于提示工程、智能体评估及生产环境可靠性的宝贵经验。对于希望构建复杂 AI 系统的开发者来说，这是一份极具参考价值的实战指南。

## 正文


Claude 现在拥有[研究能力](https://www.anthropic.com/news/research)，可以跨网络、Google Workspace 和任何集成进行搜索，以完成复杂任务。

这个多智能体系统从原型到生产的旅程教会了我们关于系统架构、工具设计和提示工程的重要经验。多智能体系统由多个智能体（在循环中自主使用工具的 LLM）协同工作组成。我们的研究功能涉及一个根据用户查询规划研究过程的智能体，然后使用工具创建并行搜索信息的子智能体。具有多个智能体的系统在智能体协调、评估和可靠性方面带来了新的挑战。

本文分解了对我们有效的原则——我们希望你在构建自己的多智能体系统时会发现它们很有用。

### 多智能体系统的优势

研究工作涉及开放式问题，很难提前预测所需的步骤。你无法为探索复杂主题硬编码固定路径，因为该过程本质上是动态且路径依赖的。当人们进行研究时，他们倾向于根据发现不断更新方法，跟随调查过程中出现的线索。

这种不可预测性使得 AI 智能体特别适合研究任务。研究需要随着调查展开而灵活转向或探索相关联系。模型必须在许多轮次中自主操作，根据中间发现决定追求哪些方向。线性、一次性的流水线无法处理这些任务。

**搜索的本质是压缩**：从大量语料中提炼见解。子智能体通过在自己的上下文窗口中并行操作来促进压缩，在将最重要的令牌压缩给主导研究智能体之前，同时探索问题的不同方面。每个子智能体还提供关注点分离——不同的工具、提示和探索轨迹——这减少了路径依赖性，并实现了彻底、独立的调查。

一旦智能达到阈值，多智能体系统就成为扩展性能的重要方式。例如，尽管个体人类在过去 10 万年中变得更聪明，但人类社会在信息时代变得*指数级*更有能力，因为我们的*集体*智能和协调能力。即使是通用智能智能体在作为个体操作时也面临限制；智能体群体可以完成更多工作。

我们的内部评估显示，多智能体研究系统特别擅长涉及同时追求多个独立方向的广度优先查询。我们发现，以 Claude Opus 4 为主导智能体、Claude Sonnet 4 为子智能体的多智能体系统在我们的内部研究评估中比单智能体 Claude Opus 4 高出 90.2%。例如，当被要求识别信息技术 S&P 500 指数中所有公司的董事会成员时，多智能体系统通过将此分解为子智能体的任务找到了正确答案，而单智能体系统则因缓慢、顺序的搜索而未能找到答案。

多智能体系统之所以有效，主要是因为它们有助于花费足够的令牌来解决问题。在我们的分析中，三个因素解释了 [BrowseComp](https://openai.com/index/browsecomp/) 评估（测试浏览智能体定位难以找到信息的能力）中 95% 的性能差异。我们发现令牌使用本身解释了 80% 的差异，工具调用次数和模型选择是另外两个解释因素。这一发现验证了我们的架构，该架构将工作分配给具有独立上下文窗口的智能体，以增加并行推理的容量。最新的 Claude 模型充当令牌使用的大型效率乘数，因为升级到 Claude Sonnet 4 的性能提升比在 Claude Sonnet 3.7 上翻倍令牌预算更大。多智能体架构有效地扩展了超出单智能体限制的任务的令牌使用。


有一个缺点：在实践中，这些架构会快速消耗令牌。**在我们的数据中，智能体通常使用比聊天交互多约 4 倍的令牌，而多智能体系统使用比聊天多约 15 倍的令牌**。为了经济可行性，多智能体系统需要任务价值足够高，以支付增加的性能成本。此外，一些需要所有智能体共享相同上下文或涉及智能体之间许多依赖关系的领域目前不适合多智能体系统。例如，大多数编码任务涉及比研究更少的真正可并行任务，并且 LLM 智能体在实时协调和委派给其他智能体方面还不擅长。我们发现多智能体系统擅长涉及大量并行化、超出单个上下文窗口的信息以及与众多复杂工具接口的有价值任务。

### 研究系统架构概述

我们的研究系统使用具有**编排器-工作者模式**的多智能体架构，其中主导智能体协调过程，同时委派给并行操作的专业子智能体。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F1198befc0b33726c45692ac40f764022f4de1bf2-4584x2579.png&w=3840&q=75)

运行中的多智能体架构：用户查询流经主导智能体，该智能体创建专门的子智能体并行搜索不同方面。

当用户提交查询时，主导智能体分析它，制定策略，并生成子智能体同时探索不同方面。如上图所示，子智能体通过迭代使用搜索工具收集信息（在本例中是 2025 年的 AI 智能体公司）充当智能过滤器，然后将公司列表返回给主导智能体，以便它编译最终答案。

使用检索增强生成（RAG）的传统方法使用静态检索。也就是说，它们获取与输入查询最相似的一组块，并使用这些块生成响应。相比之下，我们的架构使用多步骤搜索，动态查找相关信息，适应新发现，并分析结果以制定高质量答案。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F3bde53c9578d74f6e05c3e515e20b910c5a8c20a-4584x4584.png&w=3840&q=75)

显示我们多智能体研究系统完整工作流程的过程图。当用户提交查询时，系统创建一个 LeadResearcher 智能体，该智能体进入迭代研究过程。LeadResearcher 首先思考方法并将计划保存到 Memory 以保持上下文，因为如果上下文窗口超过 200,000 个令牌，它将被截断，保留计划很重要。然后它创建具有特定研究任务的专门 Subagents（此处显示两个，但可以是任意数量）。每个 Subagent 独立执行网络搜索，使用交错思考评估工具结果，并将发现返回给 LeadResearcher。LeadResearcher 综合这些结果并决定是否需要更多研究——如果需要，它可以创建额外的子智能体或完善其策略。一旦收集到足够的信息，系统退出研究循环，并将所有发现传递给 CitationAgent，该智能体处理文档和研究报告以识别引用的具体位置。这确保所有声明都正确归因于其来源。最终的研究结果（包括引用）然后返回给用户。

### 研究智能体的提示工程和评估

多智能体系统与单智能体系统有重要区别，包括协调复杂性的快速增长。早期智能体犯过错误，如为简单查询生成 50 个子智能体、无休止地搜索不存在的来源，以及用过多的更新相互干扰。由于每个智能体都由提示引导，提示工程是我们改进这些行为的主要杠杆。以下是我们学到的提示智能体的一些原则：

1. **像你的智能体一样思考。** 要迭代提示，你必须理解它们的效果。为了帮助我们做到这一点，我们使用[控制台](https://console.anthropic.com/)构建了模拟，使用我们系统中的确切提示和工具，然后逐步观察智能体工作。这立即揭示了失败模式：智能体在已经有足够结果时继续、使用过于冗长的搜索查询，或选择错误的工具。有效的提示依赖于开发准确的智能体心智模型，这可以使最有影响力的变化变得明显。

2. **教导编排器如何委派。** 在我们的系统中，主导智能体将查询分解为子任务，并向子智能体描述它们。每个子智能体需要一个目标、一个输出格式、关于要使用的工具和来源的指导，以及清晰的任务边界。没有详细的任务描述，智能体会重复工作、留下空白或无法找到必要的信息。我们开始时允许主导智能体给出简单、简短的指令，如“研究半导体短缺”，但发现这些指令通常足够模糊，以至于子智能体误解任务或执行与其他智能体完全相同的搜索。例如，一个子智能体探索 2021 年汽车芯片危机，而另外 2 个重复工作调查当前 2025 年供应链，没有有效的分工。

3. **根据查询复杂性调整工作量。** 智能体难以判断不同任务的适当工作量，因此我们在提示中嵌入了缩放规则。简单的事实查找只需要 1 个智能体进行 3-10 次工具调用，直接比较可能需要 2-4 个子智能体各进行 10-15 次调用，复杂研究可能使用超过 10 个子智能体，具有明确划分的职责。这些明确的指导方针帮助主导智能体有效分配资源，并防止在简单查询上过度投资，这是我们早期版本中常见的失败模式。

4. **工具设计和选择至关重要。** 智能体-工具接口与人类-计算机接口一样关键。使用正确的工具是高效的——通常，这是严格必要的。例如，一个智能体在网络上搜索仅存在于 Slack 中的上下文从一开始就注定失败。随着 [MCP 服务器](https://modelcontextprotocol.io/introduction)为模型提供外部工具访问，这个问题加剧，因为智能体遇到描述质量差异很大的未见工具。我们给智能体明确的启发式方法：例如，首先检查所有可用工具，将工具使用与用户意图匹配，为广泛的外部探索搜索网络，或偏好专业工具而非通用工具。糟糕的工具描述可能使智能体走上完全错误的路径，因此每个工具都需要一个独特的目的和清晰的描述。

5. **让智能体自我改进。** 我们发现 Claude 4 模型可以成为优秀的提示工程师。当给出提示和失败模式时，它们能够诊断智能体失败的原因并提出改进建议。我们甚至创建了一个工具测试智能体——当给出有缺陷的 MCP 工具时，它尝试使用该工具，然后重写工具描述以避免失败。通过测试工具数十次，该智能体发现了关键细微差别和错误。这种改进工具人体工程学的过程使未来使用新描述的智能体的任务完成时间减少了 40%，因为它们能够避免大多数错误。

6. **先广泛，后缩小。** 搜索策略应反映专家人类研究：在深入具体细节之前探索全局。智能体通常默认使用过长、具体的查询，返回很少结果。我们通过提示智能体以简短、广泛的查询开始，评估可用内容，然后逐步缩小焦点来抵消这种趋势。

7. **引导思考过程。** [扩展思考模式](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking)引导 Claude 在可见的思考过程中输出额外的令牌，可以作为可控的草稿纸。主导智能体使用思考来规划其方法，评估哪些工具适合任务，确定查询复杂性和子智能体数量，并定义每个子智能体的角色。我们的测试显示，扩展思考改进了指令遵循、推理和效率。子智能体也进行规划，然后在工具结果后使用[交错思考](https://docs.anthropic.com/en/docs/build-with-claude/extended-thinking#interleaved-thinking)来评估质量、识别空白并完善下一个查询。这使子智能体在适应任何任务时更有效。

8. **并行工具调用改变速度和性能。** 复杂的研究任务自然涉及探索许多来源。我们的早期智能体执行顺序搜索，这非常缓慢。为了提高速度，我们引入了两种并行化：(1) 主导智能体并行生成 3-5 个子智能体，而不是串行；(2) 子智能体并行使用 3+ 个工具。这些变化将复杂查询的研究时间减少了高达 90%，使研究能够在几分钟而不是几小时内完成更多工作，同时覆盖比其他系统更多的信息。

我们的提示策略侧重于灌输良好的启发式方法，而不是严格的规则。我们研究了熟练的人类如何接近研究任务，并将这些策略编码到我们的提示中——例如将困难问题分解为更小的任务、仔细评估来源质量、根据新信息调整搜索方法，以及认识到何时专注于深度（详细调查一个主题）与广度（并行探索许多主题）。我们还通过设置明确的防护栏来主动减轻意外副作用，防止智能体失控。最后，我们专注于具有可观察性和测试用例的快速迭代循环。

### 智能体的有效评估

良好的评估对于构建可靠的 AI 应用程序至关重要，智能体也不例外。然而，评估多智能体系统提出了独特的挑战。传统评估通常假设 AI 每次遵循相同的步骤：给定输入 X，系统应遵循路径 Y 产生输出 Z。但多智能体系统不这样工作。即使起点相同，智能体也可能采取完全不同的有效路径达到目标。一个智能体可能搜索三个来源，而另一个搜索十个，或者它们可能使用不同的工具找到相同的答案。因为我们并不总是知道正确的步骤是什么，我们通常不能仅仅检查智能体是否遵循了我们预先规定的“正确”步骤。相反，我们需要灵活的评估方法，判断智能体是否在遵循合理过程的同时实现了正确的结果。

**立即开始用小样本评估。** 在智能体开发的早期，变化往往具有戏剧性影响，因为有很多低垂的果实。提示调整可能将成功率从 30% 提高到 80%。在这种效应大小下，你只需几个测试用例就能发现变化。我们开始使用一组约 20 个代表真实使用模式的查询。测试这些查询通常使我们能够清楚地看到变化的影响。我们经常听到 AI 开发团队推迟创建评估，因为他们认为只有包含数百个测试用例的大型评估才有用。然而，最好立即开始小规模测试几个示例，而不是推迟到可以构建更彻底的评估。

**LLM 作为评判员在做好时可以扩展。** 研究输出很难通过编程方式评估，因为它们是自由形式的文本，很少有一个正确答案。LLM 自然适合评分输出。我们使用了一个 LLM 评判员，根据标准评估每个输出：事实准确性（声明是否与来源匹配？）、引用准确性（引用的来源是否与声明匹配？）、完整性（是否覆盖了所有请求的方面？）、来源质量（是否使用主要来源而非低质量的次要来源？）和工具效率（是否使用了正确的工具合理次数？）。我们尝试了多个评判员评估每个组件，但发现单个 LLM 调用，使用单个提示输出 0.0-1.0 的分数和通过-失败等级，是最一致且与人类判断一致的。当评估测试用例*确实*有明确答案时，这种方法特别有效，我们可以使用 LLM 评判员简单地检查答案是否正确（即，它是否准确列出了研发预算最大的前 3 家制药公司？）。使用 LLM 作为评判员使我们能够可扩展地评估数百个输出。

**人工评估捕捉自动化遗漏的内容。** 测试智能体的人会发现评估遗漏的边缘情况。这些包括不寻常查询上的幻觉答案、系统故障或微妙的来源选择偏差。在我们的案例中，人工测试人员注意到，我们的早期智能体始终选择 SEO 优化的内容农场，而不是权威但排名较低的来源，如学术 PDF 或个人博客。在我们的提示中添加来源质量启发式方法有助于解决这个问题。即使在自动化评估的世界中，手动测试仍然必不可少。

多智能体系统具有涌现行为，这些行为在没有特定编程的情况下出现。例如，主导智能体的小变化可能不可预测地改变子智能体的行为。成功需要理解交互模式，而不仅仅是单个智能体行为。因此，这些智能体的最佳提示不仅仅是严格的指令，而是定义分工、问题解决方法和工作量预算的协作框架。正确实现这一点依赖于仔细的提示和工具设计、可靠的启发式方法、可观察性和紧密的反馈循环。请参阅[我们 Cookbook 中的开源提示](https://github.com/anthropics/anthropic-cookbook/tree/main/patterns/agents/prompts)以获取我们系统中的示例提示。

### 生产可靠性和工程挑战

在传统软件中，错误可能破坏功能、降低性能或导致中断。在智能体系统中，微小变化会级联成大的行为变化，这使得为必须在长时间运行过程中维护状态的复杂智能体编写代码异常困难。

**智能体是有状态的，错误会复合。** 智能体可以长时间运行，在许多工具调用中维护状态。这意味着我们需要持久执行代码并沿途处理错误。没有有效的缓解措施，轻微的系统故障对智能体来说可能是灾难性的。当错误发生时，我们不能仅仅从头开始：重启成本高昂且令用户沮丧。相反，我们构建了可以从智能体发生错误时恢复的系统。我们还利用模型的智能来优雅地处理问题：例如，让智能体知道工具何时失败并让它适应效果出奇地好。我们将基于 Claude 的 AI 智能体的适应性与确定性保障措施（如重试逻辑和定期检查点）结合起来。

**调试受益于新方法。** 智能体做出动态决策，即使在相同提示下，运行之间也是非确定性的。这使得调试更加困难。例如，用户会报告智能体“找不到明显的信息”，但我们无法看到原因。智能体是否使用了糟糕的搜索查询？选择了不良来源？遇到了工具故障？添加完整的生产跟踪使我们能够诊断智能体失败的原因并系统地修复问题。除了标准的可观察性之外，我们监控智能体决策模式和交互结构——所有这些都不监控单个对话的内容，以维护用户隐私。这种高级别的可观察性帮助我们诊断根本原因、发现意外行为并修复常见故障。

**部署需要仔细协调。** 智能体系统是高度状态化的提示、工具和执行逻辑网络，几乎连续运行。这意味着每当我们部署更新时，智能体可能处于其过程中的任何位置。因此，我们需要防止我们善意的代码更改破坏现有的智能体。我们不能同时将每个智能体更新到新版本。相反，我们使用[彩虹部署](https://brandon.dimcheff.com/2018/02/rainbow-deploys-with-kubernetes/)来避免中断正在运行的智能体，通过逐渐将流量从旧版本转移到新版本，同时保持两者同时运行。

**同步执行造成瓶颈。** 目前，我们的主导智能体同步执行子智能体，等待每组子智能体完成后再继续。这简化了协调，但在智能体之间的信息流中造成了瓶颈。例如，主导智能体无法引导子智能体，子智能体无法协调，整个系统可能在等待单个子智能体完成搜索时被阻塞。异步执行将实现额外的并行性：智能体并发工作，并在需要时创建新的子智能体。但这种异步性在结果协调、状态一致性和跨子智能体的错误传播方面增加了挑战。随着模型能够处理更长、更复杂的研究任务，我们预计性能提升将证明复杂性的合理性。

### 结论

在构建 AI 智能体时，最后一英里往往成为大部分旅程。在开发人员机器上工作的代码库需要大量工程才能成为可靠的生产系统。智能体系统中错误的复合性质意味着传统软件的次要问题可能完全使智能体脱轨。一个步骤失败可能导致智能体探索完全不同的轨迹，导致不可预测的结果。由于本文描述的所有原因，原型和生产之间的差距通常比预期的要大。

尽管存在这些挑战，多智能体系统已被证明对开放式研究任务有价值。用户表示，Claude 帮助他们找到了他们未曾考虑的商业机会，导航复杂的医疗保健选项，解决棘手的技术错误，并通过发现他们独自无法找到的研究联系节省了多达数天的工作。通过仔细的工程、全面的测试、注重细节的提示和工具设计、稳健的操作实践，以及对当前智能体能力有深刻理解的研究、产品和工程团队之间的紧密协作，多智能体研究系统可以可靠地大规模运行。我们已经看到这些系统正在改变人们解决复杂问题的方式。

![](https://www.anthropic.com/_next/image?url=https%3A%2F%2Fwww-cdn.anthropic.com%2Fimages%2F4zrzovbb%2Fwebsite%2F09a90e0aca54859553e93c18683e7fd33ff16d4c-2654x2148.png&w=3840&q=75)

一个 Clio 嵌入图，显示人们今天使用研究功能的最常见方式。顶级用例类别是跨专业领域开发软件系统（10%）、开发和优化专业和技术内容（8%）、制定业务增长和收入生成策略（8%）、协助学术研究和教育材料开发（7%），以及研究和验证关于人、地点或组织的信息（5%）。

### 致谢

由 Jeremy Hadfield、Barry Zhang、Kenneth Lien、Florian Scholz、Jeremy Fox 和 Daniel Ford 撰写。这项工作反映了 Anthropic 多个团队的集体努力，他们使研究功能成为可能。特别感谢 Anthropic 应用程序工程团队，他们的奉献精神将这个复杂的多智能体系统带入生产。我们也感谢早期用户的出色反馈。

以下是一些多智能体系统的额外杂项提示。

**对在多轮中改变状态的智能体进行最终状态评估。** 评估在多轮对话中修改持久状态的智能体提出了独特的挑战。与只读研究任务不同，每个操作都可能改变后续步骤的环境，创建传统评估方法难以处理的依赖关系。我们发现专注于最终状态评估而不是逐轮分析是成功的。与其判断智能体是否遵循特定过程，不如评估它是否达到了正确的最终状态。这种方法承认智能体可能找到达到相同目标的替代路径，同时仍确保它们交付预期结果。对于复杂的工作流程，将评估分解为离散的检查点，在这些检查点应发生特定的状态变化，而不是试图验证每个中间步骤。

**长视野对话管理。** 生产智能体通常进行跨越数百轮的对话，需要仔细的上下文管理策略。随着对话的延长，标准上下文窗口变得不足，需要智能压缩和记忆机制。我们实现了模式，智能体在继续新任务之前总结已完成的工作阶段，并将基本信息存储在外部记忆中。当接近上下文限制时，智能体可以通过仔细的交接生成具有干净上下文的新子智能体，同时保持连续性。此外，它们可以从记忆中检索存储的上下文（如研究计划），而不是在达到上下文限制时丢失先前的工作。这种分布式方法防止上下文溢出，同时在扩展交互中保持对话连贯性。

**子智能体输出到文件系统以最小化“传话游戏”。** 直接子智能体输出可以为某些类型的结果绕过主协调器，提高保真度和性能。与其要求子智能体通过主导智能体传达一切，不如实现工件系统，专门智能体可以创建独立持久存在的输出。子智能体调用工具将其工作存储在外部系统中，然后将轻量级引用传递回协调器。这防止了多阶段处理期间的信息丢失，并减少了通过对话历史复制大输出的令牌开销。这种模式特别适用于结构化输出，如代码、报告或数据可视化，其中子智能体的专门提示产生比通过通用协调器过滤更好的结果。

[![具有复杂几何形状和详细表面纹理的互锁拼图](https://www-cdn.anthropic.com/images/4zrzovbb/website/43abe7e54b56a891e74a8542944dfbd33f07f49c-1000x1000.svg)](https://anthropic.skilljar.com/)
